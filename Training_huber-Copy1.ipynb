{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchvision.datasets as dsets\n",
    "#import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import math as m\n",
    "import torch.nn.init\n",
    "\n",
    "gpu_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda'+':'+ str(gpu_num)) if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == ('cuda'+ ':' + str(gpu_num)) :\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   = 0.001\n",
    "training_epochs = 500\n",
    "batchsize       = 1000000 #full\n",
    "rad2deg         = 57.29577951\n",
    "deg2rad         = 0.01745329252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "trainFilename = '/media/workstation2/HDD/Daseon/sim/Missile_Simulator_chogandan_2dim_PNG/ITCG_trainset_Vm20000shoot_360.csv'\n",
    "f = open(trainFilename,'r')\n",
    "Reader = csv.reader(f)\n",
    "trainDataset_raw = []\n",
    "for row in Reader:\n",
    "    trainDataset_raw.append(row)\n",
    "trainDataset_raw = np.array(trainDataset_raw, dtype='float32')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  [ 1.0429623e+04 -3.8220634e+00  1.2230603e+02  1.9110317e+00\n",
      "  6.3654346e+01]\n",
      "std   [1.2492353e+04 3.3081369e+00 1.5931599e+02 1.3973013e+00 8.8367859e+01]\n"
     ]
    }
   ],
   "source": [
    "trainDataset_raw\n",
    "trainMean = np.mean(trainDataset_raw, axis=0)\n",
    "trainStd  = np.std(trainDataset_raw, axis=0)\n",
    "trainDataset = (trainDataset_raw - trainMean)/trainStd\n",
    "print('mean ',np.mean(trainDataset_raw, axis=0))\n",
    "print('std  ',np.std(trainDataset_raw, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70233126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batchsize, dataset):\n",
    "    if(trainDataset.shape[0]==batchsize):\n",
    "        batchNumpy = dataset\n",
    "    else:\n",
    "        batchNumpy = dataset[np.random.choice(dataset.shape[0], batchsize, replace=False), 0:]\n",
    "    \n",
    "    return torch.from_numpy(batchNumpy[0:,0:-1]), torch.from_numpy(batchNumpy[0:,-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.fc1     = nn.Linear(4, 150, bias = True)    \n",
    "        self.relu1   = nn.ReLU()\n",
    "        self.fc2     = nn.Linear(150, 300, bias = True) \n",
    "        self.relu2   = nn.ReLU()\n",
    "        self.fc3     = nn.Linear(300, 500, bias = True)\n",
    "        self.relu3   = nn.ReLU()\n",
    "        self.fc4     = nn.Linear(500, 300, bias = True)\n",
    "        self.relu4   = nn.ReLU()\n",
    "        self.fc5     = nn.Linear(300, 150, bias = True)\n",
    "        self.relu5   = nn.ReLU()\n",
    "        self.fc6     = nn.Linear(150, 1, bias = True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc6.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        out = self.fc5(out)\n",
    "        out = self.relu5(out)\n",
    "        \n",
    "        out = self.fc6(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN().to(device)\n",
    "criterion = nn.SmoothL1Loss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.900389194488525\n",
      "4.889747619628906\n",
      "4.864917755126953\n",
      "4.852269887924194\n",
      "4.85170578956604\n",
      "4.892646789550781\n",
      "4.8533616065979\n",
      "4.8824872970581055\n",
      "4.882595777511597\n",
      "4.891183137893677\n",
      "4.879257440567017\n",
      "4.874614715576172\n",
      "4.873504877090454\n",
      "4.87442421913147\n",
      "4.8743157386779785\n",
      "4.853069305419922\n",
      "4.84692120552063\n",
      "4.849628448486328\n",
      "4.848248243331909\n",
      "4.865524053573608\n",
      "4.891363143920898\n",
      "4.882126808166504\n",
      "4.876296043395996\n",
      "4.957646131515503\n",
      "4.903357028961182\n",
      "4.906477689743042\n",
      "4.86174464225769\n",
      "4.893558502197266\n",
      "4.880126714706421\n",
      "4.855976343154907\n",
      "4.887985467910767\n",
      "4.878361463546753\n",
      "4.87810206413269\n",
      "4.882338285446167\n",
      "4.873610496520996\n",
      "4.861278772354126\n",
      "4.847163200378418\n",
      "4.847432613372803\n",
      "4.879407644271851\n",
      "4.873044967651367\n",
      "4.871598482131958\n",
      "4.862567901611328\n",
      "4.910052299499512\n",
      "4.914326429367065\n",
      "4.898504972457886\n",
      "4.948851108551025\n",
      "4.946192502975464\n",
      "4.87897801399231\n",
      "4.8949854373931885\n",
      "4.897550821304321\n",
      "4.886205673217773\n",
      "4.8536906242370605\n",
      "4.851547002792358\n",
      "4.912379264831543\n",
      "4.854130268096924\n",
      "4.885519027709961\n",
      "4.855573415756226\n",
      "4.8490118980407715\n",
      "4.88435697555542\n",
      "4.877341985702515\n",
      "4.865945339202881\n",
      "4.883467674255371\n",
      "4.855560541152954\n",
      "4.859764575958252\n",
      "4.898663520812988\n",
      "4.857681512832642\n",
      "4.845540523529053\n",
      "4.84829306602478\n",
      "4.880725860595703\n",
      "4.874874591827393\n",
      "[Epoch:1] cost = 0.12725454568862915\n",
      "4.847706079483032\n",
      "4.849184274673462\n",
      "4.905582666397095\n",
      "4.890002489089966\n",
      "4.89673113822937\n",
      "4.876859664916992\n",
      "4.869989633560181\n",
      "4.854165554046631\n",
      "4.853468418121338\n",
      "4.897801399230957\n",
      "4.870961666107178\n",
      "5.061766147613525\n",
      "5.105057954788208\n",
      "4.956053972244263\n",
      "5.009677171707153\n",
      "4.93187689781189\n",
      "5.062937259674072\n",
      "4.9658522605896\n",
      "5.004118204116821\n",
      "4.954340219497681\n",
      "4.911500930786133\n",
      "5.042709827423096\n",
      "4.977652311325073\n",
      "4.978390216827393\n",
      "4.995160341262817\n",
      "4.96997332572937\n",
      "4.915753364562988\n",
      "4.985671281814575\n",
      "4.949739217758179\n",
      "4.862123489379883\n",
      "4.82192325592041\n",
      "4.841842412948608\n",
      "4.951927185058594\n",
      "5.023017883300781\n",
      "4.988131523132324\n",
      "4.937915802001953\n",
      "4.950801849365234\n",
      "4.93250584602356\n",
      "4.869427919387817\n",
      "4.851042985916138\n",
      "4.871802568435669\n",
      "4.854910135269165\n",
      "4.868546724319458\n",
      "4.849952936172485\n",
      "4.8635125160217285\n",
      "4.868658542633057\n",
      "4.827611684799194\n",
      "4.834090232849121\n",
      "4.792668104171753\n",
      "4.805577039718628\n",
      "4.851072072982788\n",
      "4.774628400802612\n",
      "4.857069969177246\n",
      "4.792852401733398\n",
      "4.852982997894287\n",
      "4.8230743408203125\n",
      "4.842696189880371\n",
      "4.84623646736145\n",
      "4.836322546005249\n",
      "4.84392237663269\n",
      "5.017712831497192\n",
      "4.870478391647339\n",
      "4.86530065536499\n",
      "4.866643667221069\n",
      "4.869533061981201\n",
      "4.996798038482666\n",
      "4.906248331069946\n",
      "4.956206321716309\n",
      "4.895650625228882\n",
      "4.825304985046387\n",
      "[Epoch:2] cost = 0.09812522679567337\n",
      "4.777056694030762\n",
      "4.79494047164917\n",
      "4.844830513000488\n",
      "4.886195182800293\n",
      "4.850907325744629\n",
      "4.804466724395752\n",
      "4.916723251342773\n",
      "4.922371864318848\n",
      "4.948809385299683\n",
      "4.900847434997559\n",
      "4.926228046417236\n",
      "4.9733359813690186\n",
      "4.905529737472534\n",
      "4.878394603729248\n",
      "4.872763633728027\n",
      "4.95303750038147\n",
      "4.850047588348389\n",
      "4.804620981216431\n",
      "4.807214021682739\n",
      "4.818719387054443\n",
      "4.8043694496154785\n",
      "4.826547622680664\n",
      "4.850752353668213\n",
      "4.837347030639648\n",
      "4.811131715774536\n",
      "4.824720621109009\n",
      "4.8541271686553955\n",
      "4.829535245895386\n",
      "4.802410840988159\n",
      "4.8484296798706055\n",
      "4.813793659210205\n",
      "4.768471956253052\n",
      "4.870992422103882\n",
      "4.8537023067474365\n",
      "4.844884157180786\n",
      "4.852072715759277\n",
      "4.843620777130127\n",
      "4.830816745758057\n",
      "4.811074256896973\n",
      "4.808544397354126\n",
      "4.81063437461853\n",
      "4.848123550415039\n",
      "4.841016054153442\n",
      "4.842668771743774\n",
      "4.8439857959747314\n",
      "4.84530234336853\n",
      "4.847053527832031\n",
      "4.821446657180786\n",
      "4.810974597930908\n",
      "4.848873615264893\n",
      "4.820837497711182\n",
      "4.851913928985596\n",
      "4.855728387832642\n",
      "4.8419694900512695\n",
      "4.8178322315216064\n",
      "4.848446369171143\n",
      "4.813809871673584\n",
      "4.815703630447388\n",
      "4.8155436515808105\n",
      "4.851716041564941\n",
      "4.824461460113525\n",
      "4.806949138641357\n",
      "4.799158811569214\n",
      "4.8085246086120605\n",
      "4.814114570617676\n",
      "4.824329853057861\n",
      "4.861575365066528\n",
      "4.841138601303101\n",
      "4.841766119003296\n",
      "4.82552170753479\n",
      "[Epoch:3] cost = 0.09265127032995224\n",
      "5.153176784515381\n",
      "4.83414626121521\n",
      "4.811403036117554\n",
      "4.837196350097656\n",
      "4.844325065612793\n",
      "4.821899175643921\n",
      "4.860868692398071\n",
      "4.850311756134033\n",
      "4.838644742965698\n",
      "4.808644771575928\n",
      "4.81637978553772\n",
      "4.8585827350616455\n",
      "4.85963773727417\n",
      "4.855879068374634\n",
      "4.836363315582275\n",
      "4.821676969528198\n",
      "4.80524468421936\n",
      "4.852370500564575\n",
      "4.80350399017334\n",
      "4.810737133026123\n",
      "4.800292015075684\n",
      "4.850119590759277\n",
      "4.846179962158203\n",
      "4.848262071609497\n",
      "4.850219011306763\n",
      "4.842322826385498\n",
      "4.824373483657837\n",
      "4.856243133544922\n",
      "4.829439163208008\n",
      "4.860573768615723\n",
      "4.835293769836426\n",
      "4.780733346939087\n",
      "4.782479763031006\n",
      "4.844533205032349\n",
      "4.848292589187622\n",
      "4.837750673294067\n",
      "4.84367036819458\n",
      "4.857056140899658\n",
      "4.846641302108765\n",
      "4.818485260009766\n",
      "4.849592447280884\n",
      "4.803477048873901\n",
      "4.786081314086914\n",
      "4.864091157913208\n",
      "4.848714351654053\n",
      "4.82541561126709\n",
      "4.791200399398804\n",
      "4.817909002304077\n",
      "4.7968854904174805\n",
      "4.803483963012695\n",
      "4.82693338394165\n",
      "4.84746527671814\n",
      "4.800007581710815\n",
      "4.843313694000244\n",
      "4.838405609130859\n",
      "4.844225883483887\n",
      "4.8460187911987305\n",
      "4.845906496047974\n",
      "4.820417165756226\n",
      "4.809577703475952\n",
      "4.7715020179748535\n",
      "4.820265293121338\n",
      "4.821539878845215\n",
      "4.811614274978638\n",
      "4.819887161254883\n",
      "4.815498352050781\n",
      "4.850364685058594\n",
      "4.813776016235352\n",
      "4.860514163970947\n",
      "4.843010425567627\n",
      "[Epoch:4] cost = 0.09103303402662277\n",
      "4.794898271560669\n",
      "4.857357025146484\n",
      "4.842117786407471\n",
      "4.842937469482422\n",
      "4.849267244338989\n",
      "4.8536999225616455\n",
      "4.850287675857544\n",
      "4.843324184417725\n",
      "4.848088264465332\n",
      "4.844236612319946\n",
      "4.839267253875732\n",
      "4.84977912902832\n",
      "4.844370365142822\n",
      "4.7901387214660645\n",
      "4.7831947803497314\n",
      "4.862020015716553\n",
      "4.8422346115112305\n",
      "4.854816913604736\n",
      "4.855567216873169\n",
      "4.843534708023071\n",
      "4.842468738555908\n",
      "4.810452699661255\n",
      "4.8638904094696045\n",
      "4.850826263427734\n",
      "4.846021413803101\n",
      "4.843000411987305\n",
      "4.827834844589233\n",
      "4.8058271408081055\n",
      "4.851128816604614\n",
      "4.844921350479126\n",
      "4.832676410675049\n",
      "4.822791337966919\n",
      "4.847058296203613\n",
      "4.848792314529419\n",
      "4.843350648880005\n",
      "4.847161293029785\n",
      "4.869999408721924\n",
      "4.844954252243042\n",
      "4.8433592319488525\n",
      "4.836257219314575\n",
      "4.853028059005737\n",
      "4.8479931354522705\n",
      "4.837876319885254\n",
      "4.8197550773620605\n",
      "4.821693658828735\n",
      "4.911530017852783\n",
      "4.911940336227417\n",
      "4.975892066955566\n",
      "4.915284633636475\n",
      "4.9434874057769775\n",
      "5.049232006072998\n",
      "4.9436705112457275\n",
      "4.933995246887207\n",
      "4.930440187454224\n",
      "4.913452386856079\n",
      "4.935817718505859\n",
      "4.875579357147217\n",
      "4.890105485916138\n",
      "4.8590734004974365\n",
      "4.984370470046997\n",
      "4.848853826522827\n",
      "4.881679534912109\n",
      "4.901802062988281\n",
      "4.958006381988525\n",
      "4.969686269760132\n",
      "4.951078653335571\n",
      "4.899026393890381\n",
      "4.866452932357788\n",
      "4.855475187301636\n",
      "4.966885089874268\n",
      "[Epoch:5] cost = 0.08987700194120407\n",
      "5.015970230102539\n",
      "4.9403040409088135\n",
      "4.900144577026367\n",
      "4.814164876937866\n",
      "4.806468725204468\n",
      "4.968554973602295\n",
      "4.941549777984619\n",
      "4.926604509353638\n",
      "4.884549856185913\n",
      "4.978976726531982\n",
      "4.88958477973938\n",
      "4.851946115493774\n",
      "4.96437931060791\n",
      "4.933034658432007\n",
      "5.005688667297363\n",
      "4.904283761978149\n",
      "4.956650018692017\n",
      "4.925830602645874\n",
      "5.015476703643799\n",
      "4.998379230499268\n",
      "4.933942556381226\n",
      "4.851236581802368\n",
      "4.844794511795044\n",
      "5.133349895477295\n",
      "4.975802183151245\n",
      "5.029769420623779\n",
      "5.124734878540039\n",
      "5.135034084320068\n",
      "5.17969536781311\n",
      "5.111246109008789\n",
      "5.1442577838897705\n",
      "4.9890546798706055\n",
      "4.972992658615112\n",
      "5.029367685317993\n",
      "5.188056468963623\n",
      "5.144305229187012\n",
      "5.101955413818359\n",
      "5.106397390365601\n",
      "5.080812692642212\n",
      "5.135663747787476\n",
      "5.007937431335449\n",
      "4.916029691696167\n",
      "4.971036911010742\n",
      "5.045411586761475\n",
      "5.064240217208862\n",
      "5.061699867248535\n",
      "5.030737638473511\n",
      "5.052801132202148\n",
      "4.988708972930908\n",
      "4.98283052444458\n",
      "4.96692419052124\n",
      "4.959646701812744\n",
      "4.9164652824401855\n",
      "4.9291672706604\n",
      "4.909990310668945\n",
      "4.906299829483032\n",
      "4.881039142608643\n",
      "4.880808591842651\n",
      "4.885493278503418\n",
      "4.900924921035767\n",
      "4.916208028793335\n",
      "4.910520076751709\n",
      "4.914300203323364\n",
      "4.919571399688721\n",
      "5.0032641887664795\n",
      "4.949777126312256\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 100000\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(int(trainDataset.shape[0]/batchsize)):\n",
    "        tbbb = time.time()\n",
    "        batch_input, batch_label = get_batch(batchsize, trainDataset)\n",
    "        print(time.time()-tbbb)\n",
    "        #print('batchpass', i)\n",
    "        batch_input           = batch_input.to(device) \n",
    "        batch_label           = batch_label.to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(batch_input)\n",
    "        \n",
    "        cost = criterion(hypothesis, batch_label)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost /(int(trainDataset.shape[0]/batchsize))\n",
    "        \n",
    "    count = 0       \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilename = '/home/workstation2/Daseon/DeepMonopulse/datTest_noNoise.csv'\n",
    "ff = open(testFilename,'r')\n",
    "Reader = csv.reader(ff)\n",
    "testDataset_raw = []\n",
    "for row in Reader:\n",
    "    testDataset_raw.append(row)\n",
    "testDataset_raw = np.array(testDataset_raw, dtype='float32')\n",
    "ff.close()\n",
    "\n",
    "testDataset = (testDataset_raw - trainMean)/trainStd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    index = np.random.choice(testDataset.shape[0], 5, replace=False)\n",
    "    inference = model(torch.from_numpy(testDataset[index, :-2]).to(device))\n",
    "    answer = testDataset_raw[index, -2:]\n",
    "    \n",
    "    inference = inference.to('cpu')\n",
    "    print('predic : ',(inference*trainStd[-2:]+trainMean[-2:])*rad2deg)\n",
    "    print('Realvl : ',answer*rad2deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = [[1,1,3],[3,8,5],[6,7,7],[8,6,2],[8,1,1]]\n",
    "kkk = np.array(kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk.random.choice(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk[np.array([1,3]),0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = np.mean(kkk, axis=0)\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.std(kkk, axis=0)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8f11d4e62c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./360WEIGHT_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), './360WEIGHT_'+str(avg_cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
