{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchvision.datasets as dsets\n",
    "#import torchvision.transforms as transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import math as m\n",
    "import torch.nn.init\n",
    "\n",
    "gpu_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda'+':'+ str(gpu_num)) if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == ('cuda'+ ':' + str(gpu_num)) :\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   = 0.001\n",
    "training_epochs = 500\n",
    "batchsize       = 1000000 #full\n",
    "rad2deg         = 57.29577951\n",
    "deg2rad         = 0.01745329252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "trainFilename = '/media/workstation2/HDD/Daseon/sim/Missile_Simulator_chogandan_2dim_PNG/ITCG_trainset_Vm20000shoot_360.csv'\n",
    "f = open(trainFilename,'r')\n",
    "Reader = csv.reader(f)\n",
    "trainDataset_raw = []\n",
    "for row in Reader:\n",
    "    trainDataset_raw.append(row)\n",
    "trainDataset_raw = np.array(trainDataset_raw, dtype='float32')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean  [ 1.0429623e+04 -3.8220634e+00  1.2230603e+02  1.9110317e+00\n",
      "  6.3654346e+01]\n",
      "std   [1.2492353e+04 3.3081369e+00 1.5931599e+02 1.3973013e+00 8.8367859e+01]\n"
     ]
    }
   ],
   "source": [
    "trainDataset_raw\n",
    "trainMean = np.mean(trainDataset_raw, axis=0)\n",
    "trainStd  = np.std(trainDataset_raw, axis=0)\n",
    "trainDataset = (trainDataset_raw - trainMean)/trainStd\n",
    "print('mean ',np.mean(trainDataset_raw, axis=0))\n",
    "print('std  ',np.std(trainDataset_raw, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70233126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batchsize, dataset):\n",
    "    if(trainDataset.shape[0]==batchsize):\n",
    "        batchNumpy = dataset\n",
    "    else:\n",
    "        batchNumpy = dataset[np.random.choice(dataset.shape[0], batchsize, replace=False), 0:]\n",
    "    \n",
    "    return torch.from_numpy(batchNumpy[0:,0:-1]), torch.from_numpy(batchNumpy[0:,-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.fc1     = nn.Linear(4, 150, bias = True)    \n",
    "        self.relu1   = nn.ReLU()\n",
    "        self.fc2     = nn.Linear(150, 300, bias = True) \n",
    "        self.relu2   = nn.ReLU()\n",
    "        self.fc3     = nn.Linear(300, 500, bias = True)\n",
    "        self.relu3   = nn.ReLU()\n",
    "        self.fc4     = nn.Linear(500, 300, bias = True)\n",
    "        self.relu4   = nn.ReLU()\n",
    "        self.fc5     = nn.Linear(300, 150, bias = True)\n",
    "        self.relu5   = nn.ReLU()\n",
    "        self.fc6     = nn.Linear(150, 1, bias = True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc5.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc6.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        out = self.fc5(out)\n",
    "        out = self.relu5(out)\n",
    "        \n",
    "        out = self.fc6(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN().to(device)\n",
    "criterion = nn.SmoothL1Loss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-93bb5fbb66dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbatch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print('batchpass', i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_input\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mbatch_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1a9511e61788>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batchsize, dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatchNumpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbatchNumpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchNumpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchNumpy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_epochs = 100000\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(int(trainDataset.shape[0]/batchsize)):\n",
    "        tbbb = time.time()\n",
    "        batch_input, batch_label = get_batch(batchsize, trainDataset)\n",
    "        print(time.time()-tbbb)\n",
    "        #print('batchpass', i)\n",
    "        batch_input           = batch_input.to(device) \n",
    "        batch_label           = batch_label.to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(batch_input)\n",
    "        \n",
    "        cost = criterion(hypothesis, batch_label)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost /(int(trainDataset.shape[0]/batchsize))\n",
    "        \n",
    "    count = 0       \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFilename = '/home/workstation2/Daseon/DeepMonopulse/datTest_noNoise.csv'\n",
    "ff = open(testFilename,'r')\n",
    "Reader = csv.reader(ff)\n",
    "testDataset_raw = []\n",
    "for row in Reader:\n",
    "    testDataset_raw.append(row)\n",
    "testDataset_raw = np.array(testDataset_raw, dtype='float32')\n",
    "ff.close()\n",
    "\n",
    "testDataset = (testDataset_raw - trainMean)/trainStd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    index = np.random.choice(testDataset.shape[0], 5, replace=False)\n",
    "    inference = model(torch.from_numpy(testDataset[index, :-2]).to(device))\n",
    "    answer = testDataset_raw[index, -2:]\n",
    "    \n",
    "    inference = inference.to('cpu')\n",
    "    print('predic : ',(inference*trainStd[-2:]+trainMean[-2:])*rad2deg)\n",
    "    print('Realvl : ',answer*rad2deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk = [[1,1,3],[3,8,5],[6,7,7],[8,6,2],[8,1,1]]\n",
    "kkk = np.array(kkk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk.random.choice(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkk[np.array([1,3]),0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = np.mean(kkk, axis=0)\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = np.std(kkk, axis=0)\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './360WEIGHT_'+str(avg_cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
